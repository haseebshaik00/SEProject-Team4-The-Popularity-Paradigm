{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ASFI Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Dataset and Target Variables file paths\n",
    "repositories = './datasets/1-apache_project_status.json'\n",
    "datasetPath = './datasets/2-clean-apache-network-data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_num_nodes</th>\n",
       "      <th>s_weighted_mean_degree</th>\n",
       "      <th>s_num_component</th>\n",
       "      <th>s_avg_clustering_coef</th>\n",
       "      <th>s_largest_component</th>\n",
       "      <th>s_graph_density</th>\n",
       "      <th>t_num_dev_nodes</th>\n",
       "      <th>t_num_file_nodes</th>\n",
       "      <th>t_num_dev_per_file</th>\n",
       "      <th>t_num_file_per_dev</th>\n",
       "      <th>t_graph_density</th>\n",
       "      <th>proj_name</th>\n",
       "      <th>month</th>\n",
       "      <th>st_num_dev</th>\n",
       "      <th>t_net_overlap</th>\n",
       "      <th>s_net_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>74.153846</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687463</td>\n",
       "      <td>13</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>1.059701</td>\n",
       "      <td>106.5</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>abdera</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>34.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392751</td>\n",
       "      <td>15</td>\n",
       "      <td>0.247619</td>\n",
       "      <td>3</td>\n",
       "      <td>218</td>\n",
       "      <td>1.252294</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.417431</td>\n",
       "      <td>abdera</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.191358</td>\n",
       "      <td>0.196429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.399824</td>\n",
       "      <td>14</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "      <td>1.140351</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>abdera</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.147436</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449899</td>\n",
       "      <td>15</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>abdera</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.235897</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.163095</td>\n",
       "      <td>14</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>1.069444</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>abdera</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.170732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_num_nodes  s_weighted_mean_degree  s_num_component  \\\n",
       "0           13               74.153846                1   \n",
       "1           15               34.133333                1   \n",
       "2           18               22.000000                2   \n",
       "3           15               22.666667                1   \n",
       "4           16               19.000000                2   \n",
       "\n",
       "   s_avg_clustering_coef  s_largest_component  s_graph_density  \\\n",
       "0               0.687463                   13         0.384615   \n",
       "1               0.392751                   15         0.247619   \n",
       "2               0.399824                   14         0.156863   \n",
       "3               0.449899                   15         0.228571   \n",
       "4               0.163095                   14         0.141667   \n",
       "\n",
       "   t_num_dev_nodes  t_num_file_nodes  t_num_dev_per_file  t_num_file_per_dev  \\\n",
       "0                2               201            1.059701               106.5   \n",
       "1                3               218            1.252294                91.0   \n",
       "2                3               171            1.140351                65.0   \n",
       "3                1               195            1.000000               195.0   \n",
       "4                2                72            1.069444                38.5   \n",
       "\n",
       "   t_graph_density proj_name  month  st_num_dev  t_net_overlap  s_net_overlap  \n",
       "0         0.529851    abdera      0           1       0.000000       0.000000  \n",
       "1         0.417431    abdera      1           2       0.191358       0.196429  \n",
       "2         0.380117    abdera      2           2       0.147436       0.140000  \n",
       "3         1.000000    abdera      3           0       0.235897       0.187500  \n",
       "4         0.534722    abdera      4           1       0.139706       0.170732  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfMetrics = pd.read_csv(datasetPath)\n",
    "with open(repositories, 'r') as f:\n",
    "    reposAll = json.load(f)\n",
    "\n",
    "print(\"Metrics Dataset:\")\n",
    "display(dfMetrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASFI REPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repos Dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graduated': ['abdera',\n",
       "  'accumulo',\n",
       "  'ace',\n",
       "  'activemq',\n",
       "  'airavata',\n",
       "  'airflow',\n",
       "  'allura',\n",
       "  'ambari',\n",
       "  'oltu',\n",
       "  'any23',\n",
       "  'apex',\n",
       "  'apisix',\n",
       "  'apollo',\n",
       "  'aries',\n",
       "  'asterixdb',\n",
       "  'atlas',\n",
       "  'aurora',\n",
       "  'batchee',\n",
       "  'beam',\n",
       "  'bval',\n",
       "  'beehive',\n",
       "  'bigtop',\n",
       "  'bloodhound',\n",
       "  'brooklyn',\n",
       "  'buildr',\n",
       "  'calcite',\n",
       "  'carbondata',\n",
       "  'cassandra',\n",
       "  'cayenne',\n",
       "  'celix',\n",
       "  'chemistry',\n",
       "  'chukwa',\n",
       "  'clerezza',\n",
       "  'click',\n",
       "  'cloudstack',\n",
       "  'commonsrdf',\n",
       "  'cordova',\n",
       "  'couchdb',\n",
       "  'crunch',\n",
       "  'ctakes',\n",
       "  'curator',\n",
       "  'cxf',\n",
       "  'daffodil',\n",
       "  'datafu',\n",
       "  'datasketches',\n",
       "  'deltacloud',\n",
       "  'deltaspike',\n",
       "  'derby',\n",
       "  'devicemap',\n",
       "  'directmemory',\n",
       "  'directory',\n",
       "  'bookkeeper',\n",
       "  'dolphinscheduler',\n",
       "  'drill',\n",
       "  'druid',\n",
       "  'dubbo',\n",
       "  'eagle',\n",
       "  'ant',\n",
       "  'echarts',\n",
       "  'empire',\n",
       "  'esme',\n",
       "  'etch',\n",
       "  'falcon',\n",
       "  'felix',\n",
       "  'fineract',\n",
       "  'flex',\n",
       "  'flink',\n",
       "  'flume',\n",
       "  'fluo',\n",
       "  'freemarker',\n",
       "  'ftpserver',\n",
       "  'geode',\n",
       "  'geronimo',\n",
       "  'giraph',\n",
       "  'gobblin',\n",
       "  'gora',\n",
       "  'griffin',\n",
       "  'groovy',\n",
       "  'guacamole',\n",
       "  'hama',\n",
       "  'harmony',\n",
       "  'hawq',\n",
       "  'hcatalog',\n",
       "  'helix',\n",
       "  'pubscribe',\n",
       "  'httpd-cli',\n",
       "  'hudi',\n",
       "  'ibatis',\n",
       "  'iceberg',\n",
       "  'ignite',\n",
       "  'impala',\n",
       "  'iotdb',\n",
       "  'isis',\n",
       "  'ivy',\n",
       "  'jackrabbit',\n",
       "  'jaxme',\n",
       "  'jclouds',\n",
       "  'jdo',\n",
       "  'jena',\n",
       "  'johnzon',\n",
       "  'joshua',\n",
       "  'jspwiki',\n",
       "  'juddi',\n",
       "  'juneau',\n",
       "  'kafka',\n",
       "  'knox',\n",
       "  'kudu',\n",
       "  'kylin',\n",
       "  'lens',\n",
       "  'lenya',\n",
       "  'libcloud',\n",
       "  'log4cxx',\n",
       "  'log4cxx2',\n",
       "  'log4net',\n",
       "  'log4php',\n",
       "  'lucenenet',\n",
       "  'lucy',\n",
       "  'madlib',\n",
       "  'manifoldcf',\n",
       "  'marmotta',\n",
       "  'avalon',\n",
       "  'mesos',\n",
       "  'metamodel',\n",
       "  'metron',\n",
       "  'mnemonic',\n",
       "  'mod_ftp',\n",
       "  'mrunit',\n",
       "  'muse',\n",
       "  'myfaces',\n",
       "  'mynewt',\n",
       "  'netbeans',\n",
       "  'nifi',\n",
       "  'nutch',\n",
       "  'nuvem',\n",
       "  'ode',\n",
       "  'ofbiz',\n",
       "  'commons',\n",
       "  'olingo',\n",
       "  'omid',\n",
       "  'onami',\n",
       "  'oodt',\n",
       "  'oozie',\n",
       "  'climate',\n",
       "  'openejb',\n",
       "  'openjpa',\n",
       "  'openmeetings',\n",
       "  'opennlp',\n",
       "  'openoffice',\n",
       "  'openwebbeans',\n",
       "  'openwhisk',\n",
       "  'parquet',\n",
       "  'pdfbox',\n",
       "  'phoenix',\n",
       "  'pig',\n",
       "  'pinot',\n",
       "  'pivot',\n",
       "  'plc4x',\n",
       "  'pluto',\n",
       "  'predictionio',\n",
       "  'pulsar',\n",
       "  'qpid',\n",
       "  'ranger',\n",
       "  'rat',\n",
       "  'ratis',\n",
       "  'rave',\n",
       "  'reef',\n",
       "  'river',\n",
       "  'rocketmq',\n",
       "  'roller',\n",
       "  'rya',\n",
       "  'samza',\n",
       "  'sanselan',\n",
       "  'sentry',\n",
       "  'servicecomb',\n",
       "  'servicemix',\n",
       "  'shardingsphere',\n",
       "  'shindig',\n",
       "  'shiro',\n",
       "  'singa',\n",
       "  'sis',\n",
       "  'skywalking',\n",
       "  'sling',\n",
       "  'solr',\n",
       "  'spamassassin',\n",
       "  'spark',\n",
       "  'sqoop',\n",
       "  'stanbol',\n",
       "  'stdcxx',\n",
       "  'storm',\n",
       "  'stratos',\n",
       "  'streams',\n",
       "  'subversion',\n",
       "  'superset',\n",
       "  'synapse',\n",
       "  'syncope',\n",
       "  'systemml',\n",
       "  'tajo',\n",
       "  'tapestry',\n",
       "  'tephra',\n",
       "  'tez',\n",
       "  'thrift',\n",
       "  'tika',\n",
       "  'tinkerpop',\n",
       "  'myfaces',\n",
       "  'trafficcontrol',\n",
       "  'trafficserver',\n",
       "  'trafodion',\n",
       "  'adffaces',\n",
       "  'tuscany',\n",
       "  'tvm',\n",
       "  'twill',\n",
       "  'uima',\n",
       "  'unomi',\n",
       "  'usergrid',\n",
       "  'vcl',\n",
       "  'vxquery',\n",
       "  'struts',\n",
       "  'whirr',\n",
       "  'wicket',\n",
       "  'wink',\n",
       "  'woden',\n",
       "  'wookie',\n",
       "  'xmlbeans',\n",
       "  'zeppelin'],\n",
       " 'retired': ['agila',\n",
       "  'alois',\n",
       "  'altrmi',\n",
       "  'amaterasu',\n",
       "  'ariatosca',\n",
       "  'awf',\n",
       "  'axion',\n",
       "  'bluesky',\n",
       "  'blur',\n",
       "  'cmda',\n",
       "  'composer',\n",
       "  'concerted',\n",
       "  'corinthia',\n",
       "  'cotton',\n",
       "  'depot',\n",
       "  'droids',\n",
       "  'edgent',\n",
       "  'gearpump',\n",
       "  'gossip',\n",
       "  'graffito',\n",
       "  'hdt',\n",
       "  'heraldry',\n",
       "  'hise',\n",
       "  'horn',\n",
       "  'htrace',\n",
       "  'imperius',\n",
       "  'iota',\n",
       "  'juice',\n",
       "  'kabuki',\n",
       "  'kalumet',\n",
       "  'kato',\n",
       "  'kitty',\n",
       "  'lokahi',\n",
       "  'lucene4c',\n",
       "  'mrql',\n",
       "  'myriad',\n",
       "  'nmaven',\n",
       "  'npanday',\n",
       "  'odf',\n",
       "  'olio',\n",
       "  'openaz',\n",
       "  'photark',\n",
       "  'pirk',\n",
       "  'provisionr',\n",
       "  'quickstep',\n",
       "  'rcf',\n",
       "  'ripple',\n",
       "  's2graph',\n",
       "  's4',\n",
       "  'samoa',\n",
       "  'sirona',\n",
       "  'slider',\n",
       "  'socialsite',\n",
       "  'stonehenge',\n",
       "  'tamaya',\n",
       "  'tashi',\n",
       "  'taverna',\n",
       "  'triplesoup',\n",
       "  'tsik',\n",
       "  'wadi',\n",
       "  'warble',\n",
       "  'wave',\n",
       "  'weex',\n",
       "  'wsrp4j',\n",
       "  'xap',\n",
       "  'xmlbeans-cxx',\n",
       "  'yoko',\n",
       "  'zeta',\n",
       "  'zipkin'],\n",
       " 'incubating': ['age',\n",
       "  'annotator',\n",
       "  'bluemarlin',\n",
       "  'brpc',\n",
       "  'crail',\n",
       "  'datalab',\n",
       "  'doris',\n",
       "  'eventmesh',\n",
       "  'flagon',\n",
       "  'heron',\n",
       "  'hivemall',\n",
       "  'hop',\n",
       "  'inlong',\n",
       "  'kyuubi',\n",
       "  'liminal',\n",
       "  'linkis',\n",
       "  'livy',\n",
       "  'marvin',\n",
       "  'milagro',\n",
       "  'mxnet',\n",
       "  'nemo',\n",
       "  'nlpcraft',\n",
       "  'nuttx',\n",
       "  'pagespeed',\n",
       "  'pegasus',\n",
       "  'ponymail',\n",
       "  'sdap',\n",
       "  'sedona',\n",
       "  'shenyu',\n",
       "  'spot',\n",
       "  'streampipes',\n",
       "  'teaclave',\n",
       "  'toree',\n",
       "  'training',\n",
       "  'tuweni',\n",
       "  'wayang',\n",
       "  'yunikorn']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No. of ASFI Repos:  330\n"
     ]
    }
   ],
   "source": [
    "print(\"Repos Dataset:\")\n",
    "display(reposAll)\n",
    "\n",
    "print(f\"Total No. of ASFI Repos: \", len(reposAll.get(\"graduated\", []))+len(reposAll.get(\"incubating\", []))+len(reposAll.get(\"retired\", [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graduated and Retired Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdera',\n",
       " 'accumulo',\n",
       " 'ace',\n",
       " 'activemq',\n",
       " 'airavata',\n",
       " 'airflow',\n",
       " 'allura',\n",
       " 'ambari',\n",
       " 'oltu',\n",
       " 'any23',\n",
       " 'apex',\n",
       " 'apisix',\n",
       " 'apollo',\n",
       " 'aries',\n",
       " 'asterixdb',\n",
       " 'atlas',\n",
       " 'aurora',\n",
       " 'batchee',\n",
       " 'beam',\n",
       " 'bval',\n",
       " 'beehive',\n",
       " 'bigtop',\n",
       " 'bloodhound',\n",
       " 'brooklyn',\n",
       " 'buildr',\n",
       " 'calcite',\n",
       " 'carbondata',\n",
       " 'cassandra',\n",
       " 'cayenne',\n",
       " 'celix',\n",
       " 'chemistry',\n",
       " 'chukwa',\n",
       " 'clerezza',\n",
       " 'click',\n",
       " 'cloudstack',\n",
       " 'commonsrdf',\n",
       " 'cordova',\n",
       " 'couchdb',\n",
       " 'crunch',\n",
       " 'ctakes',\n",
       " 'curator',\n",
       " 'cxf',\n",
       " 'daffodil',\n",
       " 'datafu',\n",
       " 'datasketches',\n",
       " 'deltacloud',\n",
       " 'deltaspike',\n",
       " 'derby',\n",
       " 'devicemap',\n",
       " 'directmemory',\n",
       " 'directory',\n",
       " 'bookkeeper',\n",
       " 'dolphinscheduler',\n",
       " 'drill',\n",
       " 'druid',\n",
       " 'dubbo',\n",
       " 'eagle',\n",
       " 'ant',\n",
       " 'echarts',\n",
       " 'empire',\n",
       " 'esme',\n",
       " 'etch',\n",
       " 'falcon',\n",
       " 'felix',\n",
       " 'fineract',\n",
       " 'flex',\n",
       " 'flink',\n",
       " 'flume',\n",
       " 'fluo',\n",
       " 'freemarker',\n",
       " 'ftpserver',\n",
       " 'geode',\n",
       " 'geronimo',\n",
       " 'giraph',\n",
       " 'gobblin',\n",
       " 'gora',\n",
       " 'griffin',\n",
       " 'groovy',\n",
       " 'guacamole',\n",
       " 'hama',\n",
       " 'harmony',\n",
       " 'hawq',\n",
       " 'hcatalog',\n",
       " 'helix',\n",
       " 'pubscribe',\n",
       " 'httpd-cli',\n",
       " 'hudi',\n",
       " 'ibatis',\n",
       " 'iceberg',\n",
       " 'ignite',\n",
       " 'impala',\n",
       " 'iotdb',\n",
       " 'isis',\n",
       " 'ivy',\n",
       " 'jackrabbit',\n",
       " 'jaxme',\n",
       " 'jclouds',\n",
       " 'jdo',\n",
       " 'jena',\n",
       " 'johnzon',\n",
       " 'joshua',\n",
       " 'jspwiki',\n",
       " 'juddi',\n",
       " 'juneau',\n",
       " 'kafka',\n",
       " 'knox',\n",
       " 'kudu',\n",
       " 'kylin',\n",
       " 'lens',\n",
       " 'lenya',\n",
       " 'libcloud',\n",
       " 'log4cxx',\n",
       " 'log4cxx2',\n",
       " 'log4net',\n",
       " 'log4php',\n",
       " 'lucenenet',\n",
       " 'lucy',\n",
       " 'madlib',\n",
       " 'manifoldcf',\n",
       " 'marmotta',\n",
       " 'avalon',\n",
       " 'mesos',\n",
       " 'metamodel',\n",
       " 'metron',\n",
       " 'mnemonic',\n",
       " 'mod_ftp',\n",
       " 'mrunit',\n",
       " 'muse',\n",
       " 'myfaces',\n",
       " 'mynewt',\n",
       " 'netbeans',\n",
       " 'nifi',\n",
       " 'nutch',\n",
       " 'nuvem',\n",
       " 'ode',\n",
       " 'ofbiz',\n",
       " 'commons',\n",
       " 'olingo',\n",
       " 'omid',\n",
       " 'onami',\n",
       " 'oodt',\n",
       " 'oozie',\n",
       " 'climate',\n",
       " 'openejb',\n",
       " 'openjpa',\n",
       " 'openmeetings',\n",
       " 'opennlp',\n",
       " 'openoffice',\n",
       " 'openwebbeans',\n",
       " 'openwhisk',\n",
       " 'parquet',\n",
       " 'pdfbox',\n",
       " 'phoenix',\n",
       " 'pig',\n",
       " 'pinot',\n",
       " 'pivot',\n",
       " 'plc4x',\n",
       " 'pluto',\n",
       " 'predictionio',\n",
       " 'pulsar',\n",
       " 'qpid',\n",
       " 'ranger',\n",
       " 'rat',\n",
       " 'ratis',\n",
       " 'rave',\n",
       " 'reef',\n",
       " 'river',\n",
       " 'rocketmq',\n",
       " 'roller',\n",
       " 'rya',\n",
       " 'samza',\n",
       " 'sanselan',\n",
       " 'sentry',\n",
       " 'servicecomb',\n",
       " 'servicemix',\n",
       " 'shardingsphere',\n",
       " 'shindig',\n",
       " 'shiro',\n",
       " 'singa',\n",
       " 'sis',\n",
       " 'skywalking',\n",
       " 'sling',\n",
       " 'solr',\n",
       " 'spamassassin',\n",
       " 'spark',\n",
       " 'sqoop',\n",
       " 'stanbol',\n",
       " 'stdcxx',\n",
       " 'storm',\n",
       " 'stratos',\n",
       " 'streams',\n",
       " 'subversion',\n",
       " 'superset',\n",
       " 'synapse',\n",
       " 'syncope',\n",
       " 'systemml',\n",
       " 'tajo',\n",
       " 'tapestry',\n",
       " 'tephra',\n",
       " 'tez',\n",
       " 'thrift',\n",
       " 'tika',\n",
       " 'tinkerpop',\n",
       " 'myfaces',\n",
       " 'trafficcontrol',\n",
       " 'trafficserver',\n",
       " 'trafodion',\n",
       " 'adffaces',\n",
       " 'tuscany',\n",
       " 'tvm',\n",
       " 'twill',\n",
       " 'uima',\n",
       " 'unomi',\n",
       " 'usergrid',\n",
       " 'vcl',\n",
       " 'vxquery',\n",
       " 'struts',\n",
       " 'whirr',\n",
       " 'wicket',\n",
       " 'wink',\n",
       " 'woden',\n",
       " 'wookie',\n",
       " 'xmlbeans',\n",
       " 'zeppelin',\n",
       " 'agila',\n",
       " 'alois',\n",
       " 'altrmi',\n",
       " 'amaterasu',\n",
       " 'ariatosca',\n",
       " 'awf',\n",
       " 'axion',\n",
       " 'bluesky',\n",
       " 'blur',\n",
       " 'cmda',\n",
       " 'composer',\n",
       " 'concerted',\n",
       " 'corinthia',\n",
       " 'cotton',\n",
       " 'depot',\n",
       " 'droids',\n",
       " 'edgent',\n",
       " 'gearpump',\n",
       " 'gossip',\n",
       " 'graffito',\n",
       " 'hdt',\n",
       " 'heraldry',\n",
       " 'hise',\n",
       " 'horn',\n",
       " 'htrace',\n",
       " 'imperius',\n",
       " 'iota',\n",
       " 'juice',\n",
       " 'kabuki',\n",
       " 'kalumet',\n",
       " 'kato',\n",
       " 'kitty',\n",
       " 'lokahi',\n",
       " 'lucene4c',\n",
       " 'mrql',\n",
       " 'myriad',\n",
       " 'nmaven',\n",
       " 'npanday',\n",
       " 'odf',\n",
       " 'olio',\n",
       " 'openaz',\n",
       " 'photark',\n",
       " 'pirk',\n",
       " 'provisionr',\n",
       " 'quickstep',\n",
       " 'rcf',\n",
       " 'ripple',\n",
       " 's2graph',\n",
       " 's4',\n",
       " 'samoa',\n",
       " 'sirona',\n",
       " 'slider',\n",
       " 'socialsite',\n",
       " 'stonehenge',\n",
       " 'tamaya',\n",
       " 'tashi',\n",
       " 'taverna',\n",
       " 'triplesoup',\n",
       " 'tsik',\n",
       " 'wadi',\n",
       " 'warble',\n",
       " 'wave',\n",
       " 'weex',\n",
       " 'wsrp4j',\n",
       " 'xap',\n",
       " 'xmlbeans-cxx',\n",
       " 'yoko',\n",
       " 'zeta',\n",
       " 'zipkin']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Graduated and Retired Projects =  293\n"
     ]
    }
   ],
   "source": [
    "reposGraduatedAndRetired = reposAll[\"graduated\"] + reposAll[\"retired\"]\n",
    "display(reposGraduatedAndRetired)\n",
    "print(\"Total Graduated and Retired Projects = \", len(reposGraduatedAndRetired))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forks, Stars and PRs Scraping For Graduated and Retired Repos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo: abdera, Stars: 18, Forks: 24, PRs: 4\n",
      "Repo: accumulo, Stars: 1091, Forks: 455, PRs: 30\n",
      "Repo: ace, Stars: 27, Forks: 23, PRs: 16\n",
      "Repo: activemq, Stars: 2345, Forks: 1455, PRs: 30\n",
      "Repo: airavata, Stars: 119, Forks: 126, PRs: 30\n",
      "Repo: airflow, Stars: 39190, Forks: 14797, PRs: 30\n",
      "Repo: allura, Stars: 133, Forks: 35, PRs: 8\n",
      "Repo: ambari, Stars: 2182, Forks: 1698, PRs: 30\n",
      "Repo: oltu, Stars: 163, Forks: 120, PRs: 17\n",
      "Repo: any23, Stars: 96, Forks: 55, PRs: 30\n",
      "Error fetching data for apex: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/apex\n",
      "Repo: apisix, Stars: 14893, Forks: 2561, PRs: 30\n",
      "Error fetching data for apollo: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/apollo\n",
      "Repo: aries, Stars: 113, Forks: 158, PRs: 30\n",
      "Repo: asterixdb, Stars: 287, Forks: 143, PRs: 30\n",
      "Repo: atlas, Stars: 1908, Forks: 873, PRs: 30\n",
      "Repo: aurora, Stars: 634, Forks: 231, PRs: 30\n",
      "Error fetching data for batchee: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/batchee\n",
      "Repo: beam, Stars: 8040, Forks: 4316, PRs: 30\n",
      "Repo: bval, Stars: 44, Forks: 29, PRs: 30\n",
      "Error fetching data for beehive: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/beehive\n",
      "Repo: bigtop, Stars: 630, Forks: 520, PRs: 30\n",
      "Repo: bloodhound, Stars: 147, Forks: 30, PRs: 3\n",
      "Repo: brooklyn, Stars: 139, Forks: 67, PRs: 30\n",
      "Repo: buildr, Stars: 140, Forks: 88, PRs: 30\n",
      "Repo: calcite, Stars: 4760, Forks: 2413, PRs: 30\n",
      "Repo: carbondata, Stars: 1436, Forks: 703, PRs: 30\n",
      "Repo: cassandra, Stars: 9082, Forks: 3674, PRs: 30\n",
      "Error fetching data for cayenne: 502 Server Error: Bad Gateway for url: https://api.github.com/repos/apache/cayenne/pulls?state=all\n",
      "Repo: celix, Stars: 173, Forks: 91, PRs: 30\n",
      "Repo: chemistry, Stars: 7, Forks: 5, PRs: 0\n",
      "Repo: chukwa, Stars: 84, Forks: 40, PRs: 10\n",
      "Repo: clerezza, Stars: 36, Forks: 26, PRs: 22\n",
      "Repo: click, Stars: 14, Forks: 11, PRs: 0\n",
      "Repo: cloudstack, Stars: 2267, Forks: 1149, PRs: 30\n",
      "Error fetching data for commonsrdf: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/commonsrdf\n",
      "Repo: cordova, Stars: 655, Forks: 69, PRs: 30\n",
      "Repo: couchdb, Stars: 6431, Forks: 1046, PRs: 30\n",
      "Repo: crunch, Stars: 104, Forks: 80, PRs: 30\n",
      "Repo: ctakes, Stars: 62, Forks: 13, PRs: 17\n",
      "Repo: curator, Stars: 3133, Forks: 1246, PRs: 30\n",
      "Repo: cxf, Stars: 876, Forks: 1436, PRs: 30\n",
      "Repo: daffodil, Stars: 92, Forks: 73, PRs: 30\n",
      "Repo: datafu, Stars: 120, Forks: 65, PRs: 30\n",
      "Repo: datasketches, Stars: 95, Forks: 10, PRs: 1\n",
      "Repo: deltacloud, Stars: 72, Forks: 25, PRs: 7\n",
      "Repo: deltaspike, Stars: 151, Forks: 136, PRs: 30\n",
      "Repo: derby, Stars: 353, Forks: 140, PRs: 30\n",
      "Error fetching data for devicemap: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/devicemap\n",
      "Repo: directmemory, Stars: 53, Forks: 27, PRs: 19\n",
      "Error fetching data for directory: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/directory\n",
      "Repo: bookkeeper, Stars: 1919, Forks: 913, PRs: 30\n",
      "Repo: dolphinscheduler, Stars: 13322, Forks: 4735, PRs: 30\n",
      "Repo: drill, Stars: 1961, Forks: 980, PRs: 30\n",
      "Repo: druid, Stars: 13639, Forks: 3731, PRs: 30\n",
      "Repo: dubbo, Stars: 40819, Forks: 26504, PRs: 30\n",
      "Repo: eagle, Stars: 411, Forks: 179, PRs: 30\n",
      "Repo: ant, Stars: 432, Forks: 441, PRs: 30\n",
      "Repo: echarts, Stars: 62125, Forks: 19696, PRs: 30\n",
      "Error fetching data for empire: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/empire\n",
      "Repo: esme, Stars: 17, Forks: 8, PRs: 6\n",
      "Repo: etch, Stars: 17, Forks: 8, PRs: 0\n",
      "Repo: falcon, Stars: 103, Forks: 111, PRs: 30\n",
      "Repo: felix, Stars: 286, Forks: 318, PRs: 30\n",
      "Repo: fineract, Stars: 1486, Forks: 1807, PRs: 30\n",
      "Error fetching data for flex: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/flex\n",
      "Repo: flink, Stars: 24635, Forks: 13558, PRs: 30\n",
      "Repo: flume, Stars: 2545, Forks: 1575, PRs: 30\n",
      "Repo: fluo, Stars: 188, Forks: 72, PRs: 30\n",
      "Repo: freemarker, Stars: 1015, Forks: 270, PRs: 30\n",
      "Repo: ftpserver, Stars: 79, Forks: 54, PRs: 10\n",
      "Repo: geode, Stars: 2301, Forks: 684, PRs: 30\n",
      "Repo: geronimo, Stars: 37, Forks: 22, PRs: 28\n",
      "Repo: giraph, Stars: 618, Forks: 301, PRs: 30\n",
      "Repo: gobblin, Stars: 2237, Forks: 750, PRs: 30\n",
      "Repo: gora, Stars: 121, Forks: 129, PRs: 30\n",
      "Repo: griffin, Stars: 1152, Forks: 588, PRs: 30\n",
      "Repo: groovy, Stars: 5264, Forks: 1899, PRs: 30\n",
      "Error fetching data for guacamole: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/guacamole\n",
      "Repo: hama, Stars: 131, Forks: 71, PRs: 20\n",
      "Repo: harmony, Stars: 86, Forks: 38, PRs: 0\n",
      "Repo: hawq, Stars: 694, Forks: 328, PRs: 30\n",
      "Repo: hcatalog, Stars: 60, Forks: 45, PRs: 2\n",
      "Repo: helix, Stars: 476, Forks: 228, PRs: 30\n",
      "Error fetching data for pubscribe: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/pubscribe\n",
      "Error fetching data for httpd-cli: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/httpd-cli\n",
      "Repo: hudi, Stars: 5692, Forks: 2466, PRs: 30\n",
      "Error fetching data for ibatis: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/ibatis\n",
      "Repo: iceberg, Stars: 7028, Forks: 2431, PRs: 30\n",
      "Repo: ignite, Stars: 4896, Forks: 1912, PRs: 30\n",
      "Repo: impala, Stars: 1194, Forks: 520, PRs: 30\n",
      "Repo: iotdb, Stars: 5711, Forks: 1042, PRs: 30\n",
      "Repo: isis, Stars: 867, Forks: 306, PRs: 30\n",
      "Error fetching data for ivy: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/ivy\n",
      "Repo: jackrabbit, Stars: 348, Forks: 219, PRs: 30\n",
      "Error fetching data for jaxme: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/jaxme\n",
      "Repo: jclouds, Stars: 206, Forks: 143, PRs: 30\n",
      "Error fetching data for jdo: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/jdo\n",
      "Repo: jena, Stars: 1151, Forks: 662, PRs: 30\n",
      "Repo: johnzon, Stars: 53, Forks: 66, PRs: 30\n",
      "Repo: joshua, Stars: 106, Forks: 63, PRs: 30\n",
      "Repo: jspwiki, Stars: 107, Forks: 102, PRs: 30\n",
      "Repo: juddi, Stars: 18, Forks: 14, PRs: 30\n",
      "Repo: juneau, Stars: 83, Forks: 39, PRs: 30\n",
      "Repo: kafka, Stars: 29661, Forks: 14238, PRs: 30\n",
      "Repo: knox, Stars: 195, Forks: 255, PRs: 30\n",
      "Repo: kudu, Stars: 1862, Forks: 653, PRs: 30\n",
      "Repo: kylin, Stars: 3682, Forks: 1530, PRs: 30\n",
      "Repo: lens, Stars: 60, Forks: 94, PRs: 30\n",
      "Repo: lenya, Stars: 18, Forks: 7, PRs: 10\n",
      "Repo: libcloud, Stars: 2053, Forks: 925, PRs: 30\n",
      "Error fetching data for log4cxx: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/log4cxx\n",
      "Error fetching data for log4cxx2: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/log4cxx2\n",
      "Error fetching data for log4net: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/log4net\n",
      "Error fetching data for log4php: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/log4php\n",
      "Repo: lucenenet, Stars: 2280, Forks: 642, PRs: 30\n",
      "Repo: lucy, Stars: 99, Forks: 24, PRs: 30\n",
      "Repo: madlib, Stars: 465, Forks: 148, PRs: 30\n",
      "Repo: manifoldcf, Stars: 77, Forks: 64, PRs: 30\n",
      "Repo: marmotta, Stars: 54, Forks: 51, PRs: 30\n",
      "Error fetching data for avalon: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/avalon\n",
      "Repo: mesos, Stars: 5296, Forks: 1675, PRs: 30\n",
      "Repo: metamodel, Stars: 156, Forks: 148, PRs: 30\n",
      "Repo: metron, Stars: 856, Forks: 508, PRs: 30\n",
      "Repo: mnemonic, Stars: 120, Forks: 63, PRs: 30\n",
      "Error fetching data for mod_ftp: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/mod_ftp\n",
      "Repo: mrunit, Stars: 38, Forks: 24, PRs: 1\n",
      "Error fetching data for muse: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/muse\n",
      "Repo: myfaces, Stars: 120, Forks: 71, PRs: 30\n",
      "Error fetching data for mynewt: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/mynewt\n",
      "Repo: netbeans, Stars: 2764, Forks: 879, PRs: 30\n",
      "Repo: nifi, Stars: 5164, Forks: 2772, PRs: 30\n",
      "Repo: nutch, Stars: 2988, Forks: 1252, PRs: 30\n",
      "Repo: nuvem, Stars: 2, Forks: 3, PRs: 2\n",
      "Repo: ode, Stars: 44, Forks: 60, PRs: 8\n",
      "Repo: ofbiz, Stars: 785, Forks: 555, PRs: 27\n",
      "Error fetching data for commons: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/commons\n",
      "Error fetching data for olingo: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/olingo\n",
      "Error fetching data for omid: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/omid\n",
      "Repo: onami, Stars: 11, Forks: 3, PRs: 0\n",
      "Repo: oodt, Stars: 63, Forks: 60, PRs: 30\n",
      "Repo: oozie, Stars: 723, Forks: 473, PRs: 30\n",
      "Repo: climate, Stars: 140, Forks: 113, PRs: 30\n",
      "Repo: openejb, Stars: 12, Forks: 26, PRs: 30\n",
      "Repo: openjpa, Stars: 138, Forks: 135, PRs: 30\n",
      "Repo: openmeetings, Stars: 647, Forks: 263, PRs: 30\n",
      "Repo: opennlp, Stars: 1486, Forks: 462, PRs: 30\n",
      "Repo: openoffice, Stars: 1008, Forks: 326, PRs: 30\n",
      "Repo: openwebbeans, Stars: 68, Forks: 61, PRs: 30\n",
      "Repo: openwhisk, Stars: 6623, Forks: 1173, PRs: 30\n",
      "Error fetching data for parquet: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/parquet\n",
      "Repo: pdfbox, Stars: 2774, Forks: 886, PRs: 30\n",
      "Repo: phoenix, Stars: 1036, Forks: 1007, PRs: 30\n",
      "Repo: pig, Stars: 687, Forks: 449, PRs: 30\n",
      "Repo: pinot, Stars: 5669, Forks: 1341, PRs: 30\n",
      "Repo: pivot, Stars: 42, Forks: 24, PRs: 0\n",
      "Repo: plc4x, Stars: 1377, Forks: 432, PRs: 30\n",
      "Repo: pluto, Stars: 4, Forks: 7, PRs: 11\n",
      "Repo: predictionio, Stars: 12529, Forks: 1927, PRs: 30\n",
      "Repo: pulsar, Stars: 14495, Forks: 3621, PRs: 30\n",
      "Repo: qpid, Stars: 128, Forks: 86, PRs: 10\n",
      "Repo: ranger, Stars: 937, Forks: 1004, PRs: 30\n",
      "Error fetching data for rat: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/rat\n",
      "Repo: ratis, Stars: 1340, Forks: 428, PRs: 30\n",
      "Repo: rave, Stars: 15, Forks: 11, PRs: 23\n",
      "Repo: reef, Stars: 95, Forks: 96, PRs: 30\n",
      "Error fetching data for river: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/river\n",
      "Repo: rocketmq, Stars: 21612, Forks: 11808, PRs: 30\n",
      "Repo: roller, Stars: 124, Forks: 132, PRs: 30\n",
      "Repo: rya, Stars: 109, Forks: 75, PRs: 30\n",
      "Repo: samza, Stars: 823, Forks: 336, PRs: 30\n",
      "Repo: sanselan, Stars: 35, Forks: 16, PRs: 3\n",
      "Repo: sentry, Stars: 120, Forks: 88, PRs: 11\n",
      "Error fetching data for servicecomb: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/servicecomb\n",
      "Repo: servicemix, Stars: 160, Forks: 152, PRs: 30\n",
      "Repo: shardingsphere, Stars: 20116, Forks: 6792, PRs: 30\n",
      "Repo: shindig, Stars: 66, Forks: 68, PRs: 7\n",
      "Repo: shiro, Stars: 4360, Forks: 2313, PRs: 30\n",
      "Repo: singa, Stars: 3383, Forks: 1248, PRs: 30\n",
      "Repo: sis, Stars: 100, Forks: 45, PRs: 30\n",
      "Repo: skywalking, Stars: 24155, Forks: 6567, PRs: 30\n",
      "Repo: sling, Stars: 219, Forks: 258, PRs: 30\n",
      "Repo: solr, Stars: 1328, Forks: 699, PRs: 30\n",
      "Repo: spamassassin, Stars: 285, Forks: 77, PRs: 2\n",
      "Repo: spark, Stars: 40744, Forks: 28550, PRs: 30\n",
      "Repo: sqoop, Stars: 978, Forks: 586, PRs: 30\n",
      "Repo: stanbol, Stars: 112, Forks: 74, PRs: 30\n",
      "Repo: stdcxx, Stars: 63, Forks: 25, PRs: 0\n",
      "Repo: storm, Stars: 6614, Forks: 4077, PRs: 30\n",
      "Repo: stratos, Stars: 158, Forks: 115, PRs: 30\n",
      "Repo: streams, Stars: 77, Forks: 46, PRs: 30\n",
      "Repo: subversion, Stars: 588, Forks: 179, PRs: 18\n",
      "Repo: superset, Stars: 64987, Forks: 14678, PRs: 30\n",
      "Repo: synapse, Stars: 71, Forks: 57, PRs: 30\n",
      "Repo: syncope, Stars: 281, Forks: 186, PRs: 30\n",
      "Repo: systemml, Stars: 1041, Forks: 481, PRs: 30\n",
      "Repo: tajo, Stars: 134, Forks: 111, PRs: 30\n",
      "Error fetching data for tapestry: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/tapestry\n",
      "Error fetching data for tephra: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/tephra\n",
      "Repo: tez, Stars: 491, Forks: 428, PRs: 30\n",
      "Repo: thrift, Stars: 10659, Forks: 4051, PRs: 30\n",
      "Repo: tika, Stars: 2836, Forks: 805, PRs: 30\n",
      "Repo: tinkerpop, Stars: 2021, Forks: 822, PRs: 30\n",
      "Repo: myfaces, Stars: 120, Forks: 71, PRs: 30\n",
      "Repo: trafficcontrol, Stars: 1122, Forks: 345, PRs: 30\n",
      "Repo: trafficserver, Stars: 1845, Forks: 820, PRs: 30\n",
      "Repo: trafodion, Stars: 246, Forks: 151, PRs: 30\n",
      "Error fetching data for adffaces: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/adffaces\n",
      "Error fetching data for tuscany: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/tuscany\n",
      "Repo: tvm, Stars: 12111, Forks: 3533, PRs: 30\n",
      "Repo: twill, Stars: 69, Forks: 70, PRs: 30\n",
      "Error fetching data for uima: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/uima\n",
      "Repo: unomi, Stars: 296, Forks: 132, PRs: 30\n",
      "Repo: usergrid, Stars: 990, Forks: 426, PRs: 30\n",
      "Repo: vcl, Stars: 12, Forks: 19, PRs: 11\n",
      "Repo: vxquery, Stars: 20, Forks: 29, PRs: 30\n",
      "Repo: struts, Stars: 1312, Forks: 824, PRs: 30\n",
      "Repo: whirr, Stars: 93, Forks: 58, PRs: 7\n",
      "Repo: wicket, Stars: 751, Forks: 393, PRs: 30\n",
      "Repo: wink, Stars: 20, Forks: 22, PRs: 12\n",
      "Error fetching data for woden: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/woden\n",
      "Repo: wookie, Stars: 6, Forks: 5, PRs: 15\n",
      "Repo: xmlbeans, Stars: 54, Forks: 62, PRs: 20\n",
      "Repo: zeppelin, Stars: 6468, Forks: 2816, PRs: 30\n",
      "Error fetching data for agila: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/agila\n",
      "Error fetching data for alois: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/alois\n",
      "Error fetching data for altrmi: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/altrmi\n",
      "Error fetching data for amaterasu: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/amaterasu\n",
      "Error fetching data for ariatosca: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/ariatosca\n",
      "Error fetching data for awf: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/awf\n",
      "Error fetching data for axion: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/axion\n",
      "Error fetching data for bluesky: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/bluesky\n",
      "Error fetching data for blur: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/blur\n",
      "Error fetching data for cmda: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/cmda\n",
      "Error fetching data for composer: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/composer\n",
      "Error fetching data for concerted: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/concerted\n",
      "Error fetching data for corinthia: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/corinthia\n",
      "Error fetching data for cotton: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/cotton\n",
      "Error fetching data for depot: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/depot\n",
      "Error fetching data for droids: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/droids\n",
      "Error fetching data for edgent: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/edgent\n",
      "Error fetching data for gearpump: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/gearpump\n",
      "Error fetching data for gossip: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/gossip\n",
      "Error fetching data for graffito: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/graffito\n",
      "Error fetching data for hdt: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/hdt\n",
      "Error fetching data for heraldry: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/heraldry\n",
      "Error fetching data for hise: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/hise\n",
      "Error fetching data for horn: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/horn\n",
      "Error fetching data for htrace: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/htrace\n",
      "Error fetching data for imperius: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/imperius\n",
      "Error fetching data for iota: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/iota\n",
      "Error fetching data for juice: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/juice\n",
      "Error fetching data for kabuki: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/kabuki\n",
      "Repo: kalumet, Stars: 7, Forks: 5, PRs: 8\n",
      "Error fetching data for kato: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/kato\n",
      "Error fetching data for kitty: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/kitty\n",
      "Error fetching data for lokahi: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/lokahi\n",
      "Error fetching data for lucene4c: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/lucene4c\n",
      "Error fetching data for mrql: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/mrql\n",
      "Error fetching data for myriad: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/myriad\n",
      "Error fetching data for nmaven: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/nmaven\n",
      "Repo: npanday, Stars: 14, Forks: 14, PRs: 16\n",
      "Error fetching data for odf: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/odf\n",
      "Error fetching data for olio: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/olio\n",
      "Error fetching data for openaz: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/openaz\n",
      "Repo: photark, Stars: 10, Forks: 6, PRs: 6\n",
      "Error fetching data for pirk: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/pirk\n",
      "Error fetching data for provisionr: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/provisionr\n",
      "Error fetching data for quickstep: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/quickstep\n",
      "Error fetching data for rcf: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/rcf\n",
      "Error fetching data for ripple: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/ripple\n",
      "Error fetching data for s2graph: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/s2graph\n",
      "Error fetching data for s4: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/s4\n",
      "Error fetching data for samoa: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/samoa\n",
      "Repo: sirona, Stars: 110, Forks: 46, PRs: 17\n",
      "Error fetching data for slider: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/slider\n",
      "Error fetching data for socialsite: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/socialsite\n",
      "Error fetching data for stonehenge: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/stonehenge\n",
      "Error fetching data for tamaya: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/tamaya\n",
      "Repo: tashi, Stars: 9, Forks: 7, PRs: 2\n",
      "Error fetching data for taverna: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/taverna\n",
      "Error fetching data for triplesoup: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/triplesoup\n",
      "Error fetching data for tsik: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/tsik\n",
      "Error fetching data for wadi: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/wadi\n",
      "Error fetching data for warble: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/warble\n",
      "Error fetching data for wave: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/wave\n",
      "Error fetching data for weex: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/weex\n",
      "Error fetching data for wsrp4j: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/wsrp4j\n",
      "Error fetching data for xap: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/xap\n",
      "Error fetching data for xmlbeans-cxx: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/xmlbeans-cxx\n",
      "Error fetching data for yoko: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/yoko\n",
      "Error fetching data for zeta: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/zeta\n",
      "Repo: zipkin, Stars: 17143, Forks: 3102, PRs: 30\n"
     ]
    }
   ],
   "source": [
    "# Graduated and Retired\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from config import GITHUB_TOKEN\n",
    "\n",
    "GITHUB_API_URL = \"https://api.github.com/repos/apache/{}\"\n",
    "headers = {\"Authorization\": f\"Bearer {GITHUB_TOKEN}\"}\n",
    "\n",
    "repo_data = []\n",
    "failed_repos = []\n",
    "\n",
    "for repo in reposGraduatedAndRetired:\n",
    "    try:\n",
    "        response = requests.get(GITHUB_API_URL.format(repo), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        stars = data.get(\"stargazers_count\", 0)\n",
    "        forks = data.get(\"forks_count\", 0)\n",
    "        pr_response = requests.get(GITHUB_API_URL.format(repo) + \"/pulls?state=all\", headers=headers)\n",
    "        pr_response.raise_for_status()\n",
    "        pr_count = len(pr_response.json())\n",
    "        repo_data.append({\n",
    "            \"repo\": repo,\n",
    "            \"stars\": stars,\n",
    "            \"forks\": forks,\n",
    "            \"pull_requests\": pr_count\n",
    "        })\n",
    "        print(f\"Repo: {repo}, Stars: {stars}, Forks: {forks}, PRs: {pr_count}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {repo}: {e}\")\n",
    "        failed_repos.append({\"repo\": repo, \"error\": str(e)})\n",
    "\n",
    "with open(\"./datasets/3-repo_data.json\", \"w\") as f:\n",
    "    json.dump(repo_data, f, indent=4)\n",
    "\n",
    "with open(\"./datasets/4-failed_repos.json\", \"w\") as f:\n",
    "    json.dump(failed_repos, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Scraped Graduated and Retired Projects: 192\n",
      "Number of Repositories Failed to be Scraped: 101\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def count_json_objects(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        if isinstance(data, list):\n",
    "            return len(data)\n",
    "x_count = count_json_objects(\"./datasets/3-repo_data.json\")\n",
    "y_count = count_json_objects(\"./datasets/4-failed_repos.json\")\n",
    "\n",
    "print(f\"Total Scraped Graduated and Retired Projects: {x_count}\")\n",
    "print(f\"Number of Repositories Failed to be Scraped: {y_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle failed Graduated and Retired Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo: Apex, Stars: 349, Forks: 173, PRs: 30\n",
      "Repo: Apollo, Stars: 153, Forks: 70, PRs: 10\n",
      "Repo: Batchee, Stars: 14, Forks: 17, PRs: 20\n",
      "Repo: Commonsrdf, Stars: 47, Forks: 42, PRs: 30\n",
      "Repo: Devicemap, Stars: 9, Forks: 5, PRs: 0\n",
      "Repo: Empire, Stars: 83, Forks: 23, PRs: 16\n",
      "Repo: Flex, Stars: 355, Forks: 144, PRs: 30\n",
      "Repo: Guacamole, Stars: 1477, Forks: 737, PRs: 30\n",
      "Repo: Pubscribe, Stars: 4, Forks: 3, PRs: 9\n",
      "Repo: Ivy, Stars: 69, Forks: 112, PRs: 30\n",
      "Repo: Jdo, Stars: 31, Forks: 18, PRs: 30\n",
      "Repo: Log4cxx, Stars: 282, Forks: 124, PRs: 30\n",
      "Repo: Log4net, Stars: 877, Forks: 334, PRs: 30\n",
      "Repo: Log4php, Stars: 100, Forks: 81, PRs: 22\n",
      "Repo: Mynewt, Stars: 857, Forks: 370, PRs: 30\n",
      "Repo: Commons, Stars: 2777, Forks: 1625, PRs: 30\n",
      "Repo: Olingo, Stars: 169, Forks: 191, PRs: 30\n",
      "Repo: Omid, Stars: 88, Forks: 60, PRs: 30\n",
      "Repo: Parquet, Stars: 2754, Forks: 1453, PRs: 30\n",
      "Repo: Rat, Stars: 30, Forks: 48, PRs: 30\n",
      "Repo: Servicecomb, Stars: 1921, Forks: 824, PRs: 30\n",
      "Repo: Tapestry, Stars: 122, Forks: 95, PRs: 30\n",
      "Repo: Tephra, Stars: 32, Forks: 50, PRs: 30\n",
      "Repo: Tuscany, Stars: 7, Forks: 5, PRs: 0\n",
      "Repo: Uima, Stars: 64, Forks: 37, PRs: 30\n",
      "Repo: Amaterasu, Stars: 0, Forks: 1, PRs: 0\n",
      "Repo: Ariatosca, Stars: 28, Forks: 45, PRs: 30\n",
      "Repo: Axion, Stars: 12, Forks: 23, PRs: 30\n",
      "Repo: Blur, Stars: 33, Forks: 31, PRs: 6\n",
      "Repo: Cmda, Stars: 1, Forks: 3, PRs: 0\n",
      "Repo: Composer, Stars: 69, Forks: 21, PRs: 30\n",
      "Repo: Concerted, Stars: 11, Forks: 5, PRs: 6\n",
      "Repo: Corinthia, Stars: 16, Forks: 5, PRs: 0\n",
      "Repo: Cotton, Stars: 91, Forks: 22, PRs: 0\n",
      "Repo: Edgent, Stars: 216, Forks: 135, PRs: 30\n",
      "Repo: Gearpump, Stars: 296, Forks: 91, PRs: 30\n",
      "Repo: Gossip, Stars: 251, Forks: 110, PRs: 30\n",
      "Repo: Hdt, Stars: 7, Forks: 7, PRs: 1\n",
      "Repo: Horn, Stars: 28, Forks: 16, PRs: 30\n",
      "Repo: Htrace, Stars: 106, Forks: 82, PRs: 13\n",
      "Repo: Iota, Stars: 33, Forks: 30, PRs: 30\n",
      "Repo: Mrql, Stars: 17, Forks: 15, PRs: 30\n",
      "Repo: Myriad, Stars: 154, Forks: 68, PRs: 30\n",
      "Repo: Nmaven, Stars: 154, Forks: 68, PRs: 30\n",
      "Repo: Openaz, Stars: 17, Forks: 25, PRs: 7\n",
      "Repo: Pirk, Stars: 57, Forks: 26, PRs: 30\n",
      "Repo: Provisionr, Stars: 5, Forks: 7, PRs: 0\n",
      "Repo: Quickstep, Stars: 95, Forks: 63, PRs: 30\n",
      "Repo: Ripple, Stars: 171, Forks: 53, PRs: 30\n",
      "Repo: S2graph, Stars: 269, Forks: 64, PRs: 30\n",
      "Repo: S4, Stars: 42, Forks: 17, PRs: 2\n",
      "Repo: Samoa, Stars: 248, Forks: 106, PRs: 30\n",
      "Repo: Slider, Stars: 78, Forks: 72, PRs: 8\n",
      "Repo: Tamaya, Stars: 44, Forks: 32, PRs: 30\n",
      "Repo: Taverna, Stars: 16, Forks: 9, PRs: 8\n",
      "Repo: Warble, Stars: 1, Forks: 2, PRs: 1\n",
      "Repo: Wave, Stars: 217, Forks: 98, PRs: 27\n",
      "Repo: Weex, Stars: 13716, Forks: 1805, PRs: 30\n",
      "Skipping Xmlbeans, already in data.\n",
      "Repo: Yoko, Stars: 3, Forks: 13, PRs: 2\n",
      "Repo: Zeta, Stars: 47, Forks: 14, PRs: 4\n",
      "Repo: Wsrp4j, Stars: 37, Forks: 41, PRs: 30\n",
      "Repo: Httpd-cli, Stars: 3656, Forks: 1169, PRs: 30\n",
      "Repo: Log4cxx2, Stars: 282, Forks: 124, PRs: 30\n",
      "Repo: Ibatis, Stars: 19997, Forks: 12924, PRs: 30\n",
      "Repo: Jaxme, Stars: 31659, Forks: 2947, PRs: 30\n",
      "Repo: Avalon, Stars: 0, Forks: 0, PRs: 0\n",
      "Repo: Juice, Stars: 1118, Forks: 76, PRs: 30\n",
      "Repo: Kabuki, Stars: 73, Forks: 3, PRs: 2\n",
      "Repo: Beehive, Stars: 1, Forks: 1, PRs: 5\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from config import GITHUB_TOKEN\n",
    "\n",
    "custom_repos = {\n",
    "    \"Ibatis\": \"https://github.com/mybatis/mybatis-3\",\n",
    "    \"Jaxme\": \"https://github.com/jax-ml/jax\",\n",
    "    \"Avalon\": \"https://github.com/avalonphp/avalon\",\n",
    "    \"Juice\": \"https://github.com/fff-rs/juice\",\n",
    "    \"Kabuki\": \"https://github.com/carllerche/kabuki\",\n",
    "    \"Beehive\": \"https://github.com/moparisthebest/beehive\"\n",
    "}\n",
    "\n",
    "apache_repos = {\n",
    "    \"Apex\": \"apex-core\",\n",
    "    \"Apollo\": \"activemq-apollo\",\n",
    "    \"Batchee\": \"incubator-batchee\",\n",
    "    \"Commonsrdf\": \"commons-rdf\",\n",
    "    \"Devicemap\": \"devicemap-browsermap\",\n",
    "    \"Empire\": \"empire-db\",\n",
    "    \"Flex\": \"flex-sdk\",\n",
    "    \"Guacamole\": \"guacamole-client\",\n",
    "    \"Pubscribe\": \"infrastructure-pypubsub\",\n",
    "    \"Ivy\": \"ant-ivy\",\n",
    "    \"Jdo\": \"db-jdo\",\n",
    "    \"Log4cxx\": \"logging-log4cxx\",\n",
    "    \"Log4net\": \"logging-log4net\",\n",
    "    \"Log4php\": \"logging-log4php\",\n",
    "    \"Mynewt\": \"mynewt-core\",\n",
    "    \"Commons\": \"commons-lang\",\n",
    "    \"Olingo\": \"olingo-odata4\",\n",
    "    \"Omid\": \"incubator-omid\",\n",
    "    \"Parquet\": \"parquet-mr\",\n",
    "    \"Rat\": \"creadur-rat\",\n",
    "    \"Servicecomb\": \"servicecomb-java-chassis\",\n",
    "    \"Tapestry\": \"tapestry-5\",\n",
    "    \"Tephra\": \"incubator-tephra\",\n",
    "    \"Tuscany\": \"tuscany-sca-cpp\",\n",
    "    \"Uima\": \"uima-uimaj\",\n",
    "    \"Amaterasu\": \"incubator-retired-amaterasu-site\",\n",
    "    \"Ariatosca\": \"incubator-ariatosca\",\n",
    "    \"Axion\": \"ws-axiom\",\n",
    "    \"Blur\": \"incubator-blur\",\n",
    "    \"Cmda\": \"incubator-cmda\",\n",
    "    \"Composer\": \"openwhisk-composer\",\n",
    "    \"Concerted\": \"incubator-concerted\",\n",
    "    \"Corinthia\": \"incubator-corinthia\",\n",
    "    \"Cotton\": \"incubator-cotton\",\n",
    "    \"Edgent\": \"incubator-edgent\",\n",
    "    \"Gearpump\": \"incubator-gearpump\",\n",
    "    \"Gossip\": \"incubator-gossip\",\n",
    "    \"Hdt\": \"incubator-hdt\",\n",
    "    \"Horn\": \"incubator-horn\",\n",
    "    \"Htrace\": \"incubator-retired-htrace\",\n",
    "    \"Iota\": \"incubator-iota\",\n",
    "    \"Mrql\": \"incubator-retired-mrql\",\n",
    "    \"Myriad\": \"incubator-myriad\",\n",
    "    \"Nmaven\": \"incubator-myriad\",\n",
    "    \"Openaz\": \"incubator-retired-openaz\",\n",
    "    \"Pirk\": \"incubator-retired-pirk\",\n",
    "    \"Provisionr\": \"incubator-retired-provisionr\",\n",
    "    \"Quickstep\": \"incubator-retired-quickstep\",\n",
    "    \"Ripple\": \"incubator-retired-ripple\",\n",
    "    \"S2graph\": \"incubator-s2graph\",\n",
    "    \"S4\": \"incubator-retired-s4\",\n",
    "    \"Samoa\": \"incubator-samoa\",\n",
    "    \"Slider\": \"incubator-retired-slider\",\n",
    "    \"Tamaya\": \"incubator-retired-tamaya\",\n",
    "    \"Taverna\": \"incubator-taverna-engine\",\n",
    "    \"Warble\": \"incubator-warble-website\",\n",
    "    \"Wave\": \"incubator-retired-wave\",\n",
    "    \"Weex\": \"incubator-weex\",\n",
    "    \"Xmlbeans\": \"xmlbeans\",\n",
    "    \"Yoko\": \"geronimo-yoko\",\n",
    "    \"Zeta\": \"zetacomponents\",\n",
    "    \"Wsrp4j\": \"ws-wss4j\",\n",
    "    \"Httpd-cli\": \"httpd\",\n",
    "    \"Log4cxx2\": \"logging-log4cxx\",\n",
    "}\n",
    "\n",
    "GITHUB_API_URL = \"https://api.github.com/repos/apache/{}\"\n",
    "headers = {\"Authorization\": f\"Bearer {GITHUB_TOKEN}\"}\n",
    "\n",
    "repo_data = {}\n",
    "\n",
    "if os.path.exists(\"./datasets/3-repo_data.json\"):\n",
    "    with open(\"./datasets/3-repo_data.json\", \"r\") as f:\n",
    "        try:\n",
    "            existing_data = json.load(f)\n",
    "            if isinstance(existing_data, list):\n",
    "                repo_data = {item[\"repo\"]: item for item in existing_data}\n",
    "            elif isinstance(existing_data, dict):\n",
    "                repo_data = existing_data\n",
    "        except json.JSONDecodeError:\n",
    "            repo_data = {}\n",
    "failed_repos = []\n",
    "for key, repo in apache_repos.items():\n",
    "    if repo in repo_data:\n",
    "        print(f\"Skipping {key}, already in data.\")\n",
    "        continue\n",
    "    try:\n",
    "        response = requests.get(GITHUB_API_URL.format(repo), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        stars = data.get(\"stargazers_count\", 0)\n",
    "        forks = data.get(\"forks_count\", 0)\n",
    "        pr_response = requests.get(GITHUB_API_URL.format(repo) + \"/pulls?state=all\", headers=headers)\n",
    "        pr_response.raise_for_status()\n",
    "        pr_count = len(pr_response.json())\n",
    "        repo_data[key] = {\n",
    "            \"repo\": key,\n",
    "            \"stars\": stars,\n",
    "            \"forks\": forks,\n",
    "            \"pull_requests\": pr_count\n",
    "        }\n",
    "        print(f\"Repo: {key}, Stars: {stars}, Forks: {forks}, PRs: {pr_count}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {key}: {e}\")\n",
    "        failed_repos.append({\"repo\": key, \"error\": str(e)})\n",
    "for key, url in custom_repos.items():\n",
    "    if url in repo_data:\n",
    "        print(f\"Skipping {key}, already in data.\")\n",
    "        continue\n",
    "    try:\n",
    "        response = requests.get(f\"https://api.github.com/repos/{url.replace('https://github.com/', '')}\", headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        stars = data.get(\"stargazers_count\", 0)\n",
    "        forks = data.get(\"forks_count\", 0)\n",
    "        pr_response = requests.get(f\"https://api.github.com/repos/{url.replace('https://github.com/', '')}/pulls?state=all\", headers=headers)\n",
    "        pr_response.raise_for_status()\n",
    "        pr_count = len(pr_response.json())\n",
    "        repo_data[key] = {\n",
    "            \"repo\": key,\n",
    "            \"stars\": stars,\n",
    "            \"forks\": forks,\n",
    "            \"pull_requests\": pr_count\n",
    "        }\n",
    "        print(f\"Repo: {key}, Stars: {stars}, Forks: {forks}, PRs: {pr_count}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {key}: {e}\")\n",
    "        failed_repos.append({\"repo\": key, \"error\": str(e)})\n",
    "\n",
    "with open(\"./datasets/3-repo_data.json\", \"w\") as f:\n",
    "    json.dump(repo_data, f, indent=4)\n",
    "\n",
    "with open(\"./datasets/4-failed_repos.json\", \"w\") as f:\n",
    "    json.dump(failed_repos, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Scraped Graduated and Retired Projects: 260\n",
      "Number of Graduated and Retired Projects Failed to be Scraped: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def count_json_objects(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        if isinstance(data, dict):\n",
    "            return len(data.keys())\n",
    "        elif isinstance(data, list):\n",
    "            return len(data)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "x_count = count_json_objects(\"./datasets/3-repo_data.json\")\n",
    "y_count = count_json_objects(\"./datasets/4-failed_repos.json\")\n",
    "print(f\"Final Scraped Graduated and Retired Projects: {x_count}\")\n",
    "print(f\"Number of Graduated and Retired Projects Failed to be Scraped: {y_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incubating Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'annotator',\n",
       " 'bluemarlin',\n",
       " 'brpc',\n",
       " 'crail',\n",
       " 'datalab',\n",
       " 'doris',\n",
       " 'eventmesh',\n",
       " 'flagon',\n",
       " 'heron',\n",
       " 'hivemall',\n",
       " 'hop',\n",
       " 'inlong',\n",
       " 'kyuubi',\n",
       " 'liminal',\n",
       " 'linkis',\n",
       " 'livy',\n",
       " 'marvin',\n",
       " 'milagro',\n",
       " 'mxnet',\n",
       " 'nemo',\n",
       " 'nlpcraft',\n",
       " 'nuttx',\n",
       " 'pagespeed',\n",
       " 'pegasus',\n",
       " 'ponymail',\n",
       " 'sdap',\n",
       " 'sedona',\n",
       " 'shenyu',\n",
       " 'spot',\n",
       " 'streampipes',\n",
       " 'teaclave',\n",
       " 'toree',\n",
       " 'training',\n",
       " 'tuweni',\n",
       " 'wayang',\n",
       " 'yunikorn']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Projects in Incubating Phase =  37\n"
     ]
    }
   ],
   "source": [
    "reposIncubating = reposAll[\"incubating\"]\n",
    "display(reposIncubating)\n",
    "print(\"Total Projects in Incubating Phase = \", len(reposIncubating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forks, Stars and PRs Scraping For Incubating Repositories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo: age, Stars: 3398, Forks: 424, PRs: 30\n",
      "Error fetching data for annotator: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/annotator\n",
      "Error fetching data for bluemarlin: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/bluemarlin\n",
      "Repo: brpc, Stars: 16848, Forks: 4016, PRs: 30\n",
      "Error fetching data for crail: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/crail\n",
      "Error fetching data for datalab: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/datalab\n",
      "Repo: doris, Stars: 13330, Forks: 3426, PRs: 30\n",
      "Repo: eventmesh, Stars: 1639, Forks: 640, PRs: 30\n",
      "Repo: flagon, Stars: 25, Forks: 15, PRs: 30\n",
      "Error fetching data for heron: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/heron\n",
      "Error fetching data for hivemall: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/hivemall\n",
      "Repo: hop, Stars: 1095, Forks: 361, PRs: 30\n",
      "Repo: inlong, Stars: 1423, Forks: 533, PRs: 30\n",
      "Repo: kyuubi, Stars: 2161, Forks: 940, PRs: 30\n",
      "Error fetching data for liminal: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/liminal\n",
      "Repo: linkis, Stars: 3347, Forks: 1168, PRs: 30\n",
      "Error fetching data for livy: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/livy\n",
      "Error fetching data for marvin: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/marvin\n",
      "Error fetching data for milagro: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/milagro\n",
      "Repo: mxnet, Stars: 20790, Forks: 6768, PRs: 30\n",
      "Error fetching data for nemo: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/nemo\n",
      "Error fetching data for nlpcraft: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/nlpcraft\n",
      "Repo: nuttx, Stars: 3145, Forks: 1267, PRs: 30\n",
      "Error fetching data for pagespeed: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/pagespeed\n",
      "Repo: pegasus, Stars: 2000, Forks: 311, PRs: 30\n",
      "Repo: ponymail, Stars: 81, Forks: 31, PRs: 30\n",
      "Error fetching data for sdap: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/sdap\n",
      "Repo: sedona, Stars: 2009, Forks: 697, PRs: 30\n",
      "Repo: shenyu, Stars: 8550, Forks: 2975, PRs: 30\n",
      "Error fetching data for spot: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/spot\n",
      "Repo: streampipes, Stars: 634, Forks: 194, PRs: 30\n",
      "Error fetching data for teaclave: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/teaclave\n",
      "Error fetching data for toree: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/toree\n",
      "Error fetching data for training: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/training\n",
      "Error fetching data for tuweni: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/tuweni\n",
      "Error fetching data for wayang: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/wayang\n",
      "Error fetching data for yunikorn: 404 Client Error: Not Found for url: https://api.github.com/repos/apache/yunikorn\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from config import GITHUB_TOKEN\n",
    "\n",
    "GITHUB_API_URL = \"https://api.github.com/repos/apache/{}\"\n",
    "headers = {\"Authorization\": f\"Bearer {GITHUB_TOKEN}\"}\n",
    "\n",
    "repo_data = []\n",
    "failed_repos = []\n",
    "\n",
    "for repo in reposIncubating:\n",
    "    try:\n",
    "        response = requests.get(GITHUB_API_URL.format(repo), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        stars = data.get(\"stargazers_count\", 0)\n",
    "        forks = data.get(\"forks_count\", 0)\n",
    "        pr_response = requests.get(GITHUB_API_URL.format(repo) + \"/pulls?state=all\", headers=headers)\n",
    "        pr_response.raise_for_status()\n",
    "        pr_count = len(pr_response.json())\n",
    "        repo_data.append({\n",
    "            \"repo\": repo,\n",
    "            \"stars\": stars,\n",
    "            \"forks\": forks,\n",
    "            \"pull_requests\": pr_count\n",
    "        })\n",
    "        print(f\"Repo: {repo}, Stars: {stars}, Forks: {forks}, PRs: {pr_count}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {repo}: {e}\")\n",
    "        failed_repos.append({\"repo\": repo, \"error\": str(e)})\n",
    "\n",
    "with open(\"./datasets/5-repo_data_incubating.json\", \"w\") as f:\n",
    "    json.dump(repo_data, f, indent=4)\n",
    "with open(\"./datasets/6-failed_repos_incubating.json\", \"w\") as f:\n",
    "    json.dump(failed_repos, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Scraped Incubating Projects: 16\n",
      "Number of Incubating Repos Failed to be Scraped: 21\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def count_json_objects(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        if isinstance(data, list):\n",
    "            return len(data)\n",
    "x_count = count_json_objects(\"./datasets/5-repo_data_incubating.json\")\n",
    "y_count = count_json_objects(\"./datasets/6-failed_repos_incubating.json\")\n",
    "\n",
    "print(f\"Total Scraped Incubating Projects: {x_count}\")\n",
    "print(f\"Number of Incubating Repos Failed to be Scraped: {y_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle failed Incubating Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator incubator-annotator\n",
      "Repo: Annotator, Stars: 231, Forks: 41, PRs: 30\n",
      "Bluemarlin incubator-bluemarlin\n",
      "Repo: Bluemarlin, Stars: 2, Forks: 7, PRs: 30\n",
      "Crail incubator-crail\n",
      "Repo: Crail, Stars: 149, Forks: 46, PRs: 30\n",
      "Datalab incubator-datalab\n",
      "Repo: Datalab, Stars: 153, Forks: 57, PRs: 30\n",
      "Heron incubator-heron\n",
      "Repo: Heron, Stars: 3630, Forks: 593, PRs: 30\n",
      "Hivemall incubator-hivemall\n",
      "Repo: Hivemall, Stars: 311, Forks: 117, PRs: 30\n",
      "Liminal incubator-liminal\n",
      "Repo: Liminal, Stars: 144, Forks: 42, PRs: 30\n",
      "Livy incubator-livy\n",
      "Repo: Livy, Stars: 904, Forks: 606, PRs: 30\n",
      "Marvin incubator-marvin\n",
      "Repo: Marvin, Stars: 101, Forks: 34, PRs: 30\n",
      "Milagro incubator-milagro\n",
      "Repo: Milagro, Stars: 42, Forks: 13, PRs: 30\n",
      "Nemo incubator-nemo\n",
      "Repo: Nemo, Stars: 112, Forks: 64, PRs: 30\n",
      "NLPCraft incubator-nlpcraft\n",
      "Repo: NLPCraft, Stars: 79, Forks: 25, PRs: 30\n",
      "Spot incubator-spot\n",
      "Repo: Spot, Stars: 350, Forks: 227, PRs: 30\n",
      "Teaclave incubator-teaclave\n",
      "Repo: Teaclave, Stars: 773, Forks: 160, PRs: 30\n",
      "Toree incubator-toree\n",
      "Repo: Toree, Stars: 741, Forks: 224, PRs: 30\n",
      "Training incubator-training\n",
      "Repo: Training, Stars: 31, Forks: 38, PRs: 30\n",
      "Tuweni incubator-tuweni\n",
      "Repo: Tuweni, Stars: 173, Forks: 83, PRs: 30\n",
      "Wayang incubator-wayang\n",
      "Repo: Wayang, Stars: 219, Forks: 92, PRs: 30\n",
      "Pagespeed incubator-pagespeed-mod\n",
      "Repo: Pagespeed, Stars: 694, Forks: 155, PRs: 30\n",
      "SDAP sdap-in-situ-data-services\n",
      "Repo: SDAP, Stars: 4, Forks: 5, PRs: 27\n",
      "Yunikorn yunikorn-core\n",
      "Repo: Yunikorn, Stars: 900, Forks: 242, PRs: 30\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from config import GITHUB_TOKEN\n",
    "\n",
    "reposIncubating = {\n",
    "    \"Annotator\": \"incubator-annotator\",\n",
    "    \"Bluemarlin\": \"incubator-bluemarlin\",\n",
    "    \"Crail\": \"incubator-crail\",\n",
    "    \"Datalab\": \"incubator-datalab\",\n",
    "    \"Heron\": \"incubator-heron\",\n",
    "    \"Hivemall\": \"incubator-hivemall\",\n",
    "    \"Liminal\": \"incubator-liminal\",\n",
    "    \"Livy\": \"incubator-livy\",\n",
    "    \"Marvin\": \"incubator-marvin\",\n",
    "    \"Milagro\": \"incubator-milagro\",\n",
    "    \"Nemo\": \"incubator-nemo\",\n",
    "    \"NLPCraft\": \"incubator-nlpcraft\",\n",
    "    \"Spot\": \"incubator-spot\",\n",
    "    \"Teaclave\": \"incubator-teaclave\",\n",
    "    \"Toree\": \"incubator-toree\",\n",
    "    \"Training\": \"incubator-training\",\n",
    "    \"Tuweni\": \"incubator-tuweni\",\n",
    "    \"Wayang\": \"incubator-wayang\",\n",
    "    \"Pagespeed\": \"incubator-pagespeed-mod\",\n",
    "    \"SDAP\": \"sdap-in-situ-data-services\",\n",
    "    \"Yunikorn\": \"yunikorn-core\"\n",
    "}\n",
    "\n",
    "GITHUB_API_URL = \"https://api.github.com/repos/apache/{}\"\n",
    "headers = {\"Authorization\": f\"Bearer {GITHUB_TOKEN}\"}\n",
    "repo_data = {}\n",
    "\n",
    "if os.path.exists(\"repo_data_incubating.json\"):\n",
    "    with open(\"repo_data_incubating.json\", \"r\") as f:\n",
    "        try:\n",
    "            existing_data = json.load(f)\n",
    "            if isinstance(existing_data, list):\n",
    "                repo_data = {item[\"repo\"]: item for item in existing_data}\n",
    "            elif isinstance(existing_data, dict):\n",
    "                repo_data = existing_data\n",
    "        except json.JSONDecodeError:\n",
    "            repo_data = {}\n",
    "\n",
    "failed_repos = []\n",
    "for key, repo in reposIncubating.items():\n",
    "    print(key, repo)\n",
    "    if repo in repo_data:\n",
    "        print(f\"Skipping {key}, already in data.\")\n",
    "        continue\n",
    "    try:\n",
    "        response = requests.get(GITHUB_API_URL.format(repo), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        stars = data.get(\"stargazers_count\", 0)\n",
    "        forks = data.get(\"forks_count\", 0)\n",
    "        pr_response = requests.get(GITHUB_API_URL.format(repo) + \"/pulls?state=all\", headers=headers)\n",
    "        pr_response.raise_for_status()\n",
    "        pr_count = len(pr_response.json())\n",
    "        repo_data[key] = {\n",
    "            \"repo\": key,\n",
    "            \"stars\": stars,\n",
    "            \"forks\": forks,\n",
    "            \"pull_requests\": pr_count\n",
    "        }\n",
    "        print(f\"Repo: {key}, Stars: {stars}, Forks: {forks}, PRs: {pr_count}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {key}: {e}\")\n",
    "        failed_repos.append({\"repo\": key, \"error\": str(e)})\n",
    "with open(\"./datasets/5-repo_data_incubating.json\", \"w\") as f:\n",
    "    json.dump(repo_data, f, indent=4)\n",
    "with open(\"./datasets/6-failed_repos_incubating.json\", \"w\") as f:\n",
    "    json.dump(failed_repos, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Scraped Incubating Projects: 37\n",
      "Number of Incubating Projects Failed to be Scraped: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def count_json_objects(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        if isinstance(data, dict):\n",
    "            return len(data.keys())\n",
    "        elif isinstance(data, list):\n",
    "            return len(data)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "x_count = count_json_objects(\"./datasets/5-repo_data_incubating.json\")\n",
    "y_count = count_json_objects(\"./datasets/6-failed_repos_incubating.json\")\n",
    "print(f\"Final Scraped Incubating Projects: {x_count}\")\n",
    "print(f\"Number of Incubating Projects Failed to be Scraped: {y_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, the final scraped graduated and retired projects are **260** which are stored in `3-repo_data.json` and total scraped incubating projects are **37** which are stored in `5-repo_data_incubating.json`!\n",
    "\n",
    "Total ASFI Repos = 297"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate PScore and Define Popularity (Target Variable-Popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>stars</th>\n",
       "      <th>forks</th>\n",
       "      <th>pull_requests</th>\n",
       "      <th>pScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>echarts</td>\n",
       "      <td>62125</td>\n",
       "      <td>19696</td>\n",
       "      <td>30</td>\n",
       "      <td>82721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>superset</td>\n",
       "      <td>64987</td>\n",
       "      <td>14678</td>\n",
       "      <td>30</td>\n",
       "      <td>80565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>spark</td>\n",
       "      <td>40744</td>\n",
       "      <td>28550</td>\n",
       "      <td>30</td>\n",
       "      <td>70194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>dubbo</td>\n",
       "      <td>40819</td>\n",
       "      <td>26504</td>\n",
       "      <td>30</td>\n",
       "      <td>68223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airflow</td>\n",
       "      <td>39190</td>\n",
       "      <td>14797</td>\n",
       "      <td>30</td>\n",
       "      <td>54887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>nuvem</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Warble</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Cmda</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Amaterasu</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Avalon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          repo  stars  forks  pull_requests  pScore\n",
       "50     echarts  62125  19696             30   82721\n",
       "160   superset  64987  14678             30   80565\n",
       "152      spark  40744  28550             30   70194\n",
       "47       dubbo  40819  26504             30   68223\n",
       "5      airflow  39190  14797             30   54887\n",
       "..         ...    ...    ...            ...     ...\n",
       "108      nuvem      2      3              2       9\n",
       "246     Warble      1      2              1       4\n",
       "220       Cmda      1      3              0       4\n",
       "216  Amaterasu      0      1              0       1\n",
       "256     Avalon      0      0              0       0\n",
       "\n",
       "[297 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate pScore\n",
    "def load_and_process(filename):\n",
    "    with open(filename, \"r\") as file:\n",
    "        try:\n",
    "            data = json.load(file)\n",
    "            if isinstance(data, dict):\n",
    "                data = list(data.values())\n",
    "            elif not isinstance(data, list):\n",
    "                raise ValueError(f\"Unexpected format in {filename}: {type(data)}\")\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(f\"Error loading {filename}: Invalid JSON format\")\n",
    "    for repo in data:\n",
    "        repo[\"pScore\"] = repo[\"stars\"] + repo[\"forks\"] + (repo[\"pull_requests\"] ** 2)\n",
    "    return data\n",
    "\n",
    "repo_data_1 = load_and_process(\"./datasets/3-repo_data.json\")\n",
    "repo_data_2 = load_and_process(\"./datasets/5-repo_data_incubating.json\")\n",
    "merged_data = repo_data_1 + repo_data_2\n",
    "\n",
    "df = pd.DataFrame(merged_data)\n",
    "df_sorted = df.sort_values(by=\"pScore\", ascending=False)\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>stars</th>\n",
       "      <th>forks</th>\n",
       "      <th>pull_requests</th>\n",
       "      <th>pScore</th>\n",
       "      <th>pScore_normalized</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>echarts</td>\n",
       "      <td>62125</td>\n",
       "      <td>19696</td>\n",
       "      <td>30</td>\n",
       "      <td>82721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>superset</td>\n",
       "      <td>64987</td>\n",
       "      <td>14678</td>\n",
       "      <td>30</td>\n",
       "      <td>80565</td>\n",
       "      <td>0.973936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>spark</td>\n",
       "      <td>40744</td>\n",
       "      <td>28550</td>\n",
       "      <td>30</td>\n",
       "      <td>70194</td>\n",
       "      <td>0.848563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>dubbo</td>\n",
       "      <td>40819</td>\n",
       "      <td>26504</td>\n",
       "      <td>30</td>\n",
       "      <td>68223</td>\n",
       "      <td>0.824736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airflow</td>\n",
       "      <td>39190</td>\n",
       "      <td>14797</td>\n",
       "      <td>30</td>\n",
       "      <td>54887</td>\n",
       "      <td>0.663520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>nuvem</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Warble</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Cmda</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Amaterasu</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Avalon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          repo  stars  forks  pull_requests  pScore  pScore_normalized  \\\n",
       "50     echarts  62125  19696             30   82721           1.000000   \n",
       "160   superset  64987  14678             30   80565           0.973936   \n",
       "152      spark  40744  28550             30   70194           0.848563   \n",
       "47       dubbo  40819  26504             30   68223           0.824736   \n",
       "5      airflow  39190  14797             30   54887           0.663520   \n",
       "..         ...    ...    ...            ...     ...                ...   \n",
       "108      nuvem      2      3              2       9           0.000109   \n",
       "246     Warble      1      2              1       4           0.000048   \n",
       "220       Cmda      1      3              0       4           0.000048   \n",
       "216  Amaterasu      0      1              0       1           0.000012   \n",
       "256     Avalon      0      0              0       0           0.000000   \n",
       "\n",
       "     popular  \n",
       "50         1  \n",
       "160        1  \n",
       "152        1  \n",
       "47         1  \n",
       "5          1  \n",
       "..       ...  \n",
       "108        0  \n",
       "246        0  \n",
       "220        0  \n",
       "216        0  \n",
       "256        0  \n",
       "\n",
       "[297 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate pScore_normalized and popularity\n",
    "min_score = df_sorted['pScore'].min()\n",
    "max_score = df_sorted['pScore'].max()\n",
    "df_sorted_norm = df_sorted\n",
    "df_sorted_norm['pScore_normalized'] = (df_sorted['pScore'] - min_score) / (max_score - min_score)\n",
    "# df_sorted_norm['popular'] = df_sorted['pScore_normalized'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "threshold = df_sorted_norm['pScore_normalized'].quantile(0.30)  # Adjust this value as per requirement\n",
    "df_sorted_norm['popular'] = df_sorted_norm['pScore_normalized'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "display(df_sorted_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity counts (1-Popular, 0-Not Popular):\n",
      "popular\n",
      "1    208\n",
      "0     89\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "popular_counts = df_sorted_norm['popular'].value_counts()\n",
    "print(\"Popularity counts (1-Popular, 0-Not Popular):\")\n",
    "print(popular_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity Dataset is stored as final-popularity-dataset.csv!\n"
     ]
    }
   ],
   "source": [
    "df_sorted_norm.to_csv('./datasets/final-popularity-dataset.csv', index=False)\n",
    "print(\"Popularity Dataset is stored as final-popularity-dataset.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>stars</th>\n",
       "      <th>forks</th>\n",
       "      <th>pull_requests</th>\n",
       "      <th>pScore</th>\n",
       "      <th>pScore_normalized</th>\n",
       "      <th>popular</th>\n",
       "      <th>s_num_nodes</th>\n",
       "      <th>s_weighted_mean_degree</th>\n",
       "      <th>s_num_component</th>\n",
       "      <th>...</th>\n",
       "      <th>t_num_dev_nodes</th>\n",
       "      <th>t_num_file_nodes</th>\n",
       "      <th>t_num_dev_per_file</th>\n",
       "      <th>t_num_file_per_dev</th>\n",
       "      <th>t_graph_density</th>\n",
       "      <th>proj_name</th>\n",
       "      <th>month</th>\n",
       "      <th>st_num_dev</th>\n",
       "      <th>t_net_overlap</th>\n",
       "      <th>s_net_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>echarts</td>\n",
       "      <td>62125</td>\n",
       "      <td>19696</td>\n",
       "      <td>30</td>\n",
       "      <td>82721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>535</td>\n",
       "      <td>1.220561</td>\n",
       "      <td>163.250000</td>\n",
       "      <td>0.305140</td>\n",
       "      <td>echarts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>echarts</td>\n",
       "      <td>62125</td>\n",
       "      <td>19696</td>\n",
       "      <td>30</td>\n",
       "      <td>82721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>414</td>\n",
       "      <td>1.881643</td>\n",
       "      <td>194.750000</td>\n",
       "      <td>0.470411</td>\n",
       "      <td>echarts</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>echarts</td>\n",
       "      <td>62125</td>\n",
       "      <td>19696</td>\n",
       "      <td>30</td>\n",
       "      <td>82721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>606</td>\n",
       "      <td>1.110561</td>\n",
       "      <td>224.333333</td>\n",
       "      <td>0.370187</td>\n",
       "      <td>echarts</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017894</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>echarts</td>\n",
       "      <td>62125</td>\n",
       "      <td>19696</td>\n",
       "      <td>30</td>\n",
       "      <td>82721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>510</td>\n",
       "      <td>1.039216</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>echarts</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025705</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>echarts</td>\n",
       "      <td>62125</td>\n",
       "      <td>19696</td>\n",
       "      <td>30</td>\n",
       "      <td>82721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>echarts</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057878</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      repo  stars  forks  pull_requests  pScore  pScore_normalized  popular  \\\n",
       "0  echarts  62125  19696             30   82721                1.0        1   \n",
       "1  echarts  62125  19696             30   82721                1.0        1   \n",
       "2  echarts  62125  19696             30   82721                1.0        1   \n",
       "3  echarts  62125  19696             30   82721                1.0        1   \n",
       "4  echarts  62125  19696             30   82721                1.0        1   \n",
       "\n",
       "   s_num_nodes  s_weighted_mean_degree  s_num_component  ...  t_num_dev_nodes  \\\n",
       "0            4                5.000000                1  ...                4   \n",
       "1            5                4.800000                2  ...                4   \n",
       "2            6                9.333333                1  ...                3   \n",
       "3            8               28.000000                1  ...                2   \n",
       "4            7               11.428571                1  ...                3   \n",
       "\n",
       "   t_num_file_nodes  t_num_dev_per_file  t_num_file_per_dev  t_graph_density  \\\n",
       "0               535            1.220561          163.250000         0.305140   \n",
       "1               414            1.881643          194.750000         0.470411   \n",
       "2               606            1.110561          224.333333         0.370187   \n",
       "3               510            1.039216          265.000000         0.519608   \n",
       "4                60            1.500000           30.000000         0.500000   \n",
       "\n",
       "   proj_name  month  st_num_dev t_net_overlap  s_net_overlap  \n",
       "0    echarts      0           0      0.000000       0.000000  \n",
       "1    echarts      1           0      0.064156       0.000000  \n",
       "2    echarts      2           0      0.017894       0.222222  \n",
       "3    echarts      3           0      0.025705       0.250000  \n",
       "4    echarts      4           0      0.057878       0.291667  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged successfully and saved as 'final-dataset.csv'!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_popularity = pd.read_csv('./datasets/final-popularity-dataset.csv')\n",
    "df_apache = pd.read_csv('./datasets/2-clean-apache-network-data.csv')\n",
    "df_popularity['repo'] = df_popularity['repo'].astype(str).str.lower().str.strip()\n",
    "df_apache['proj_name'] = df_apache['proj_name'].astype(str).str.lower().str.strip()\n",
    "merged_df = pd.merge(df_popularity, df_apache, left_on='repo', right_on='proj_name', how='inner')\n",
    "merged_df.to_csv('./datasets/final-dataset.csv', index=False)\n",
    "\n",
    "display(merged_df.head())\n",
    "print(\"Datasets merged successfully and saved as 'final-dataset.csv'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
